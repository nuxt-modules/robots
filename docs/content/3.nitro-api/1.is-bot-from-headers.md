---
title: isBotFromHeaders()
description: Detect and classify bots from HTTP headers in Nitro server context.
---

## Introduction

The `isBotFromHeaders()`{lang="ts"} utility function allows you to detect and classify bots using HTTP header analysis.

This is useful for implementing bot-specific logic on the server side, such as serving different content to search engines or blocking malicious automation tools.

## API

```ts
function isBotFromHeaders(headers: HeadersRecord): BotDetectionResult

interface BotDetectionResult {
  isBot: boolean
  data?: {
    botType: string
    botName: string 
    trusted: boolean
  }
}

type HeadersRecord = Record<string, string | string[] | undefined>
```

### Arguments

- `headers: HeadersRecord`{lang="ts"}: HTTP headers object (similar to h3's getHeaders result).

### Returns

- `isBot: boolean`{lang="ts"}: Whether a bot was detected.
- `data?: object`{lang="ts"}: Bot details (only present when `isBot` is `true`):
  - `botType: string`{lang="ts"}: Bot category ('search-engine', 'social', 'ai', etc.)
  - `botName: string`{lang="ts"}: Specific bot name ('googlebot', 'twitterbot', etc.)  
  - `trusted: boolean`{lang="ts"}: Whether this is a legitimate/trusted bot

## Example

```ts twoslash [server/middleware/bot-handler.ts]
import { isBotFromHeaders } from '@nuxtjs/robots/util'

export default defineEventHandler(async (event) => {
  const headers = getHeaders(event)
  const detection = isBotFromHeaders(headers)
  
  if (detection.isBot) {
    console.log(`Bot detected: ${detection.data.botName}`)
    
    if (detection.data.trusted) {
      // Allow trusted bots (search engines, social media)
      setHeader(event, 'X-Bot-Allowed', 'true')
    } else {
      // Handle untrusted bots (scrapers, security scanners)
      if (detection.data.botType === 'security-scanner') {
        throw createError({ statusCode: 403, statusMessage: 'Access Denied' })
      }
    }
  }
})
```

## Bot Categories

The function detects the following bot categories:

- **search-engine**: Google, Bing, Yandex crawlers (trusted)
- **social**: Twitter, Facebook, LinkedIn bots (trusted)
- **seo**: Ahrefs, SEMrush, Majestic tools (trusted)
- **ai**: GPT, Claude, Perplexity crawlers (trusted)
- **automation**: Selenium, Puppeteer, WebDriver (untrusted)
- **security-scanner**: nmap, Nikto, ZGrab (untrusted)
- **http-tool**: curl, wget, Python requests (untrusted)
- **header-anomaly**: Missing or inconsistent headers (untrusted)

## Detection Methods

The function analyzes multiple aspects of HTTP headers:

- User agent pattern matching against known bot signatures
- Missing standard browser headers (Accept, Accept-Language, etc.)
- Client hint inconsistencies (mobile vs desktop)
- Browser-specific header validation (Chrome client hints)